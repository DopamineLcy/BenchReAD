{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.measure import label, regionprops\n",
    "from operator import attrgetter\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from glob import glob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_root = './data/brazilian-ophthalmological/1.0.1/fundus_photos'\n",
    "raw_files = glob(raw_root + '/*.jpg', recursive=True)\n",
    "\n",
    "print(len(raw_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_crop(img, min_idx, max_idx):\n",
    "    crop = np.zeros(np.array(max_idx, dtype='int16') - np.array(min_idx, dtype='int16'), dtype=img.dtype)\n",
    "    img_shape, start, crop_shape = np.array(img.shape), np.array(min_idx, dtype='int16'), np.array(crop.shape),\n",
    "    end = start + crop_shape\n",
    "    # Calculate crop slice positions\n",
    "    crop_low = np.clip(0 - start, a_min=0, a_max=crop_shape)\n",
    "    crop_high = crop_shape - np.clip(end - img_shape, a_min=0, a_max=crop_shape)\n",
    "    crop_slices = (slice(low, high) for low, high in zip(crop_low, crop_high))\n",
    "    # Calculate img slice positions\n",
    "    pos = np.clip(start, a_min=0, a_max=img_shape)\n",
    "    end = np.clip(end, a_min=0, a_max=img_shape)\n",
    "    img_slices = (slice(low, high) for low, high in zip(pos, end))\n",
    "    crop[tuple(crop_slices)] = img[tuple(img_slices)]\n",
    "    return crop\n",
    "\n",
    "\n",
    "def fundus_crop(image, shape=[512, 512], margin=5):\n",
    "    mask = (image.sum(axis=-1) > 30)\n",
    "    mask = label(mask)\n",
    "    regions = regionprops(mask)\n",
    "    region = max(regions, key=attrgetter('area'))\n",
    "\n",
    "    len = (np.array(region.bbox[2:4]) - np.array(region.bbox[0:2])).max()\n",
    "    bbox = np.concatenate([np.array(region.centroid) - len / 2, np.array(region.centroid) + len / 2]).astype('int16')\n",
    "\n",
    "    image_b = fill_crop(image, [bbox[0] - margin, bbox[1] - margin, 0], [bbox[2] + margin, bbox[3] + margin, 3])\n",
    "    image_b = cv2.resize(image_b, shape, interpolation=cv2.INTER_LINEAR)\n",
    "    return image_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_single_image(cur_path):\n",
    "    try:\n",
    "        image = cv2.imread(cur_path)\n",
    "        image_crop = fundus_crop(image, shape=[512, 512], margin=5)\n",
    "        save_path = cur_path.replace('fundus_photos', 'fundus_photos_preprocessed')\n",
    "        os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "        cv2.imwrite(save_path, image_crop)\n",
    "    except Exception as e:\n",
    "        print(f\"error {cur_path}: {str(e)}\")\n",
    "\n",
    "def process_images_parallel(raw_files, num_threads=8):\n",
    "    with ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
    "        list(tqdm(executor.map(process_single_image, raw_files), \n",
    "                 total=len(raw_files), \n",
    "                 desc=\"processing\"))\n",
    "\n",
    "process_images_parallel(raw_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
